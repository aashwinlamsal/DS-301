---
title: "DS301_HW2"
author: "Aashwin Lamsal"
date: "2/16/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## DS 301 Homework 2

## Question 1
```{r}
#PART A
library(ISLR)
#viewing the dataset
#head(Auto) 
#names(Auto)

#Y=mpg, and is going to become our response vector
Y = Auto$mpg

#dim(Auto) used to check the dimensions of the entire table, 392 rows by 9 columns

n = dim(Auto)[1] #the dimensions of the response vector are 392 rows by 1 column

n
#X=horsepower, and is going to become our design matrix

X = cbind(rep(1,n), Auto$horsepower) #first column is full of 1's always
xdim = dim(X) # the dimensions of the design matrix is 392 rows by 2 columns

xdim

#PART B
#Calculating X transpose times X
XtX = t(X)%*%X

XtX

#Calculating X transpose times Y
XtY = t(X)%*%Y

XtY

#Calculating the inverse of X transpose times X
XtX_inverse = solve(XtX)

XtX_inverse

#PART C
#Calculating least squares estimate, beta hat
betaHat = XtX_inverse %*% XtY

betaHat

#model = lm(Y~X, Auto)
#summary(model) lm output used here to double check my results

#PART D
#plot(x=Auto$horsepower, y = Auto$mpg) plotting the relationshsip between mpg and horsepower

#The response vector doesn't change, but the values in the design matrix will be squared to address the quadratic nature. The model continues to be a simple linear regression model with Y = mpg and X = horsepower^2.

Xsquared = cbind(rep(1,n), (Auto$horsepower)^2)
#newXtX
newXtX = t(Xsquared)%*%Xsquared

newXtX
#newXtY

newXtY = t(Xsquared)%*%Y

newXtY

#newXtX_inverse
newXtX_inverse = solve(newXtX)

newXtX_inverse

#newbetaHat
newbetaHat = newXtX_inverse %*% newXtY

newbetaHat

#model = lm(Y~Xsquared, Auto)
#summary(model)  again, using lm output used here to double check my results
```
### The dimensions of the response vector are 392 rows by 1 column.The dimensions of the design matrix is 392 rows by 2 columns. 

### Answers for Part B, C, and D was displayed in the output, and written down on the attached notebook paper.

## Question 2
```{r}
#PART A
library(jtools)

patient = read.table("/Users/aashw/Documents/DS-301/patient.txt")
names(patient) = c("satisf","age","severe","anxiety")
#head(patient) checking the first 6 rows

#Response vector
Y = patient$satisf
n = dim(patient)[1]

#Design matrix
X = cbind(rep(1,n),patient$age, patient$severe, patient$anxiety)


#Fitting the model
model=lm(Y~age+severe+anxiety,data=patient)
print("Output table (numbers are rounded from the lm output due to the jtools table, the exact numbers are on the notebook paper)")
summ(model)

#PART B
#Conducting an F-Test on all of our predictors

p = 4
alpha = 0.05
#Test statistic
f_star = 30.05
df1 = 3
df2 = 42
#p-value 
pValue= pf(f_star,df1,df2,lower.tail=FALSE)
print("P-value:")
pValue

#Decision Rule
print("Is the P-Value less than our significance level? If true, reject the null hypothesis.")
pValue < alpha

#PART C
#Conducting a T-Test on beta 1
#Calculating least square estimators

XtX = t(X)%*%X

betaHat = solve(XtX)%*%t(X)%*%Y

Yhat = X%*%betaHat  
errors = Y - Yhat

#Test statistic
ts = -5.314796 #gotten from lm output summary
print("Test statistic for beta 1, as given by the lm summary:")
ts

#beta 1 p-value 

pValueB1 = 2*pt(abs(ts),n-p,lower.tail=FALSE)
print("P-Value for Beta 1:")
pValueB1

#Decision Rule
print("Is the P-Value less than our significance level? If true, reject the null hypothesis")
pValueB1 < alpha

#PART D
print("Part D: the estimate for sigma squared (sigma hat squared) is:")
sigma_hat = sqrt(sum(errors^2)/(n-p))
sigma_hat_squared = (sigma_hat)^2
sigma_hat_squared

#PART E: hand written on the notebook paper
```

### For part A, the interpretation of the summary output is on the attached notebook paper. The conclusion to part B's f-test: we reject the null hypothesis, as we found evidence that there is a relationship between a patient's satsifaction rating and, at least, one of our predictors: age, severity level, and anxiety level.

## Question 4
```{r}
#PART A
print("The diagnostics plots are as follows:")
par(mfrow=c(2,2))
plot(model)

```
## Question 5: ALL PARTS
```{r}
library(ggplot2)
df = data.frame(SigmaSquaredValues = NA)

#The for loop is for Part C
for(i in (1:5000)){
generatedValues = seq(0,10,length.out = 100)
beta0 = 2
beta1 = 3
sigma_squared = 4
n = 100

#PART A
#generating 100 observations for Y
trueY = beta0 + beta1*generatedValues + rnorm(n,0,sd=sqrt(sigma_squared))

#PART B
#obtaining an estimator for sigma squared

model5 = lm(trueY~generatedValues)
summ(model5) #used to calculate estimates for beta0 and beta1

beta0Hat = summary(model5)$coef[1,1]
beta1Hat = summary(model5)$coef[2,1]

YHat5 = beta0Hat + beta1Hat*generatedValues + rnorm(n,0,sd=sqrt(sigma_squared))

error5 = trueY - YHat5


sigma_hat_squared_5 = sqrt(sum(error5^2)/((n/2)-2))

  df[i,] = sigma_hat_squared_5
}

#PART D
ggplot(data = df, aes(x = df$SigmaSquaredValues)) + geom_histogram() + geom_vline(xintercept =4)
#hist(df[1,])
```


